# CREATE worker()

```go
package main

import (
	"fmt"
	"time"
)

// worker-pool : Design pattern to manage a group of workers (goroutines)
// used for resource-management

func worker(id int, tasks<-chan int, results chan<- int){
	for task := range tasks{
		fmt.Printf("Worker %d processing task %d\n",id,task)
		// Simulate work/ops.
		time.Sleep(time.Second)
		results <-task*2
	}
}


func main() {
	numOfWorkers := 3
	numOfJobs:= 10
	tasks:= make(chan int,numOfJobs)
	results:= make(chan int,numOfJobs)

	// Create workers
	for i:=range numOfWorkers{
		go worker(i,tasks,results)
	}

	// Send values to the tasks channel
	for i:=range numOfJobs{
		tasks<-i
	}

	close(tasks)

	// Collect the results
	for range numOfJobs{
		result:=<-results
		fmt.Println("Result:",result)
	}

// O/P:
// $ go run .
// Worker 0 processing task 0
// Worker 2 processing task 1
// Worker 1 processing task 2
// Worker 2 processing task 3
// Worker 0 processing task 4
// Worker 1 processing task 5
// Result: 2
// Result: 0
// Result: 4
// Worker 2 processing task 6
// Result: 6
// Worker 0 processing task 7
// Worker 1 processing task 8
// Result: 8
// Result: 10
// Worker 2 processing task 9
// Result: 12
// Result: 16
// Result: 14
// Result: 18

```

This is a **classic worker-pool pattern** in Go. Let’s break it down carefully, step by step, so we fully understand **what’s happening under the hood** 👇

---

## 🧩 What is a Worker Pool?

A **Worker Pool** is a concurrency design pattern used to:

* Efficiently manage a set number of goroutines (workers),
* Handle many tasks (jobs),
* Prevent spawning too many goroutines at once (which could exhaust memory/CPU).

In short:

> We have a fixed number of workers consuming jobs from a queue (channel).

---

## 🧠 Let's analyze your code line by line

---

### 🔹 Imports & Overview

```go
import (
	"fmt"
	"time"
)
```

We use:

* `fmt` → for output
* `time` → to simulate workload (via `Sleep`)

---

### 🔹 Worker Function

```go
func worker(id int, tasks <-chan int, results chan<- int) {
	for task := range tasks {
		fmt.Printf("Worker %d processing task %d\n", id, task)
		time.Sleep(time.Second)          // simulate some work
		results <- task * 2              // send processed result
	}
}
```

#### Breakdown:

* Each **worker** runs in a separate **goroutine**.
* Parameters:

  * `id` → helps us identify which worker is working.
  * `tasks <-chan int` → **receive-only channel**, from which the worker **reads jobs**.
  * `results chan<- int` → **send-only channel**, where the worker **writes results**.

#### Loop:

* `for task := range tasks` means the worker keeps pulling jobs **until the `tasks` channel is closed**.
* Each job is processed (`task * 2` simulates computation).
* The result is sent to the `results` channel.

✅ This way, multiple workers run concurrently and pick up tasks as soon as they’re available.

---

### 🔹 Main Function Setup

```go
func main() {
	numOfWorkers := 3
	numOfJobs := 10
```

We decide:

* **3 workers** → goroutines that will process jobs.
* **10 jobs** → tasks to complete.

---

### 🔹 Channels

```go
tasks := make(chan int, numOfJobs)
results := make(chan int, numOfJobs)
```

* `tasks` → buffered channel that holds incoming jobs.
* `results` → buffered channel to store computed results.

📦 Buffering prevents goroutines from blocking immediately if receivers aren’t ready.

---

### 🔹 Creating Workers

```go
for i := range numOfWorkers {
	go worker(i, tasks, results)
}
```

⚠️ **Bug here:**
`range numOfWorkers` doesn’t work since `numOfWorkers` is an `int`, not a slice/map.

✅ **Correct version:**

```go
for i := 0; i < numOfWorkers; i++ {
	go worker(i, tasks, results)
}
```

This spawns **3 worker goroutines**, each waiting on the `tasks` channel.

---

### 🔹 Sending Jobs to Workers

```go
for i := 0; i < numOfJobs; i++ {
	tasks <- i
}
close(tasks)
```

* We push **10 tasks** (`0–9`) into the `tasks` channel.
* Closing the channel signals **no more work will arrive**, allowing all workers to eventually exit their `for range tasks` loop.

---

### 🔹 Gathering Results

```go
for i := 0; i < numOfJobs; i++ {
	result := <-results
	fmt.Println("Result:", result)
}
```

* Collects **10 results** (each worker sends one after finishing).
* Print them in the main goroutine.

---

### 🔹 Full Fixed Version

```go
package main

import (
	"fmt"
	"time"
)

func worker(id int, tasks <-chan int, results chan<- int) {
	for task := range tasks {
		fmt.Printf("Worker %d processing task %d\n", id, task)
		time.Sleep(time.Second)
		results <- task * 2
	}
}

func main() {
	numOfWorkers := 3
	numOfJobs := 10

	tasks := make(chan int, numOfJobs)
	results := make(chan int, numOfJobs)

	for i := 0; i < numOfWorkers; i++ {
		go worker(i, tasks, results)
	}

	for i := 0; i < numOfJobs; i++ {
		tasks <- i
	}
	close(tasks)

	for i := 0; i < numOfJobs; i++ {
		result := <-results
		fmt.Println("Result:", result)
	}
}
```

---

### 🧮 Example Output

```
Worker 0 processing task 0
Worker 1 processing task 1
Worker 2 processing task 2
Worker 0 processing task 3
Worker 2 processing task 4
Worker 1 processing task 5
...
Result: 0
Result: 2
Result: 4
...
```

* The **order of results is non-deterministic** because workers finish at different times.

---

## ⚙️ How Worker Pool Improves Efficiency

Imagine having **1000 jobs** —
spawning 1000 goroutines would waste memory and cause scheduling overhead.

Instead:

* We spawn **N fixed workers** (say, 10),
* Feed all jobs through a channel,
* Workers pull jobs concurrently,
* Main thread collects results efficiently.

This ensures:

* **Controlled concurrency**
* **Efficient CPU utilization**
* **Reduced memory pressure**

---

## 🧠 Summary

| Concept                  | Purpose                                                   |
| ------------------------ | --------------------------------------------------------- |
| **Worker Pool**          | Pattern to manage limited goroutines processing many jobs |
| **Tasks Channel**        | Feeds jobs to workers                                     |
| **Results Channel**      | Collects processed outputs                                |
| **Close(tasks)**         | Signals no more jobs                                      |
| **Goroutines (workers)** | Execute concurrently and efficiently                      |

---
