# CREATE worker()

```go
package main

import (
	"fmt"
	"time"
)

// worker-pool : Design pattern to manage a group of workers (goroutines)
// used for resource-management

func worker(id int, tasks<-chan int, results chan<- int){
	for task := range tasks{
		fmt.Printf("Worker %d processing task %d\n",id,task)
		// Simulate work/ops.
		time.Sleep(time.Second)
		results <-task*2
	}
}


func main() {
	numOfWorkers := 3
	numOfJobs:= 10
	tasks:= make(chan int,numOfJobs)
	results:= make(chan int,numOfJobs)

	// Create workers
	for i:=range numOfWorkers{
		go worker(i,tasks,results)
	}

	// Send values to the tasks channel
	for i:=range numOfJobs{
		tasks<-i
	}

	close(tasks)

	// Collect the results
	for range numOfJobs{
		result:=<-results
		fmt.Println("Result:",result)
	}

// O/P:
// $ go run .
// Worker 0 processing task 0
// Worker 2 processing task 1
// Worker 1 processing task 2
// Worker 2 processing task 3
// Worker 0 processing task 4
// Worker 1 processing task 5
// Result: 2
// Result: 0
// Result: 4
// Worker 2 processing task 6
// Result: 6
// Worker 0 processing task 7
// Worker 1 processing task 8
// Result: 8
// Result: 10
// Worker 2 processing task 9
// Result: 12
// Result: 16
// Result: 14
// Result: 18

```

This is a **classic worker-pool pattern** in Go. Let’s break it down carefully, step by step, so we fully understand **what’s happening under the hood** 👇

---

## 🧩 What is a Worker Pool?

A **Worker Pool** is a concurrency design pattern used to:

* Efficiently manage a set number of goroutines (workers),
* Handle many tasks (jobs),
* Prevent spawning too many goroutines at once (which could exhaust memory/CPU).

In short:

> We have a fixed number of workers consuming jobs from a queue (channel).

---

## 🧠 Let's analyze your code line by line

---

### 🔹 Imports & Overview

```go
import (
	"fmt"
	"time"
)
```

We use:

* `fmt` → for output
* `time` → to simulate workload (via `Sleep`)

---

### 🔹 Worker Function

```go
func worker(id int, tasks <-chan int, results chan<- int) {
	for task := range tasks {
		fmt.Printf("Worker %d processing task %d\n", id, task)
		time.Sleep(time.Second)          // simulate some work
		results <- task * 2              // send processed result
	}
}
```

#### Breakdown:

* Each **worker** runs in a separate **goroutine**.
* Parameters:

  * `id` → helps us identify which worker is working.
  * `tasks <-chan int` → **receive-only channel**, from which the worker **reads jobs**.
  * `results chan<- int` → **send-only channel**, where the worker **writes results**.

#### Loop:

* `for task := range tasks` means the worker keeps pulling jobs **until the `tasks` channel is closed**.
* Each job is processed (`task * 2` simulates computation).
* The result is sent to the `results` channel.

✅ This way, multiple workers run concurrently and pick up tasks as soon as they’re available.

---

### 🔹 Main Function Setup

```go
func main() {
	numOfWorkers := 3
	numOfJobs := 10
```

We decide:

* **3 workers** → goroutines that will process jobs.
* **10 jobs** → tasks to complete.

---

### 🔹 Channels

```go
tasks := make(chan int, numOfJobs)
results := make(chan int, numOfJobs)
```

* `tasks` → buffered channel that holds incoming jobs.
* `results` → buffered channel to store computed results.

📦 Buffering prevents goroutines from blocking immediately if receivers aren’t ready.

---

### 🔹 Creating Workers

```go
for i := range numOfWorkers {
	go worker(i, tasks, results)
}
```

⚠️ **Bug here:**
`range numOfWorkers` doesn’t work since `numOfWorkers` is an `int`, not a slice/map.

✅ **Correct version:**

```go
for i := 0; i < numOfWorkers; i++ {
	go worker(i, tasks, results)
}
```

This spawns **3 worker goroutines**, each waiting on the `tasks` channel.

---

### 🔹 Sending Jobs to Workers

```go
for i := 0; i < numOfJobs; i++ {
	tasks <- i
}
close(tasks)
```

* We push **10 tasks** (`0–9`) into the `tasks` channel.
* Closing the channel signals **no more work will arrive**, allowing all workers to eventually exit their `for range tasks` loop.

---

### 🔹 Gathering Results

```go
for i := 0; i < numOfJobs; i++ {
	result := <-results
	fmt.Println("Result:", result)
}
```

* Collects **10 results** (each worker sends one after finishing).
* Print them in the main goroutine.

---

### 🔹 Full Fixed Version

```go
package main

import (
	"fmt"
	"time"
)

func worker(id int, tasks <-chan int, results chan<- int) {
	for task := range tasks {
		fmt.Printf("Worker %d processing task %d\n", id, task)
		time.Sleep(time.Second)
		results <- task * 2
	}
}

func main() {
	numOfWorkers := 3
	numOfJobs := 10

	tasks := make(chan int, numOfJobs)
	results := make(chan int, numOfJobs)

	for i := 0; i < numOfWorkers; i++ {
		go worker(i, tasks, results)
	}

	for i := 0; i < numOfJobs; i++ {
		tasks <- i
	}
	close(tasks)

	for i := 0; i < numOfJobs; i++ {
		result := <-results
		fmt.Println("Result:", result)
	}
}
```

---

### 🧮 Example Output

```
Worker 0 processing task 0
Worker 1 processing task 1
Worker 2 processing task 2
Worker 0 processing task 3
Worker 2 processing task 4
Worker 1 processing task 5
...
Result: 0
Result: 2
Result: 4
...
```

* The **order of results is non-deterministic** because workers finish at different times.

---

## ⚙️ How Worker Pool Improves Efficiency

Imagine having **1000 jobs** —
spawning 1000 goroutines would waste memory and cause scheduling overhead.

Instead:

* We spawn **N fixed workers** (say, 10),
* Feed all jobs through a channel,
* Workers pull jobs concurrently,
* Main thread collects results efficiently.

This ensures:

* **Controlled concurrency**
* **Efficient CPU utilization**
* **Reduced memory pressure**

---

## 🧠 Summary

| Concept                  | Purpose                                                   |
| ------------------------ | --------------------------------------------------------- |
| **Worker Pool**          | Pattern to manage limited goroutines processing many jobs |
| **Tasks Channel**        | Feeds jobs to workers                                     |
| **Results Channel**      | Collects processed outputs                                |
| **Close(tasks)**         | Signals no more jobs                                      |
| **Goroutines (workers)** | Execute concurrently and efficiently                      |

---

# REAL-WORLD example
```go
ppackage main

import (
	"fmt"
	"time"
)

// real-world app. example
type ticketRequest struct{
	personId int
	numOfTickets int
	cost int
}

// simulate processing of ticketRequests by creating workers
func ticketProcessor(requests <-chan ticketRequest, results chan<-int){
	for req := range requests{
		fmt.Printf("Processing %d ticket(s) of personId %d with total cost of %d\n", req.numOfTickets, req.personId, req.cost)

		// simulate ticket-processing time/delay
		time.Sleep(time.Second)
		results <- req.personId

	}
}

func main() {
	numOfReqs := 5
	price:=5
	ticketRequests:= make(chan ticketRequest, numOfReqs)
	ticketResults:= make(chan int)

	// Create workers/ticket-processor
	for range 3{
		go ticketProcessor(ticketRequests,ticketResults)
	}

	// Send ticket-requests
	for i:= range numOfReqs{
		ticketRequests <-ticketRequest{personId: i+1, numOfTickets:(i+1)*2, cost:(i+1)*price}
	}

	close(ticketRequests)

	for range numOfReqs{
		fmt.Printf("\n🟢Ticket for personId %d processed successfully",<-ticketResults)
	}
	
}
// O/P
// $ go run .
// Processing 2 ticket(s) of personId 1 with total cost of 5
// Processing 4 ticket(s) of personId 2 with total cost of 10
// Processing 6 ticket(s) of personId 3 with total cost of 15
// Processing 8 ticket(s) of personId 4 with total cost of 20

// 🟢Ticket for personId 3 processed successfully
// 🟢Ticket for personId 1 processed successfully
// 🟢Ticket for personId 2 processed successfullyProcessing 10 ticket(s) of personId 5 with total cost of 25

// 🟢Ticket for personId 4 processed successfully
// 🟢Ticket for personId 5 processed successfully
```

This code is a **real-world simulation** of a **worker pool pattern** in Go — where multiple *workers (goroutines)* process a stream of *tasks (ticket requests)* concurrently.

Let’s unpack this line by line — so we understand exactly **how it works**, **why it’s written this way**, and **why the output is non-sequential**.

---

## 🧩 1. Overview

This program models a **ticket booking system** where:

* Each **ticket request** comes from a person who wants to buy multiple tickets.
* Multiple **workers** (like employees or servers) process these requests *in parallel*.
* The main goroutine *sends* all ticket requests into a channel.
* The workers *pick them up*, simulate processing, and *send back results*.

The goal:
Efficiently handle multiple booking requests without blocking the main thread — **using Go’s concurrency features**.

---

## 🧱 2. Struct Definition

```go
type ticketRequest struct {
	personId     int
	numOfTickets int
	cost         int
}
```

This is a simple **data structure** holding each request’s info:

| Field          | Meaning                                           |
| -------------- | ------------------------------------------------- |
| `personId`     | Unique ID of the person booking                   |
| `numOfTickets` | How many tickets they want                        |
| `cost`         | Total cost (price per ticket × number of tickets) |

---

## ⚙️ 3. Worker Function

```go
func ticketProcessor(requests <-chan ticketRequest, results chan<- int) {
	for req := range requests {
		fmt.Printf("Processing %d ticket(s) of personId %d with total cost of %d\n",
			req.numOfTickets, req.personId, req.cost)

		time.Sleep(time.Second) // Simulate 1s processing delay
		results <- req.personId // Send back the personId when done
	}
}
```

### How it works:

* Each **worker** runs this function in its own goroutine.
* It **listens** on the `requests` channel for incoming `ticketRequest`s.
* When it receives one:

  * It prints details (person ID, ticket count, total cost).
  * Waits for a second to simulate “processing” (like payment, verification, etc.).
  * Sends the `personId` back into the `results` channel to mark completion.
* When the `requests` channel is **closed**, the `for req := range requests` loop automatically ends, and the goroutine exits.

### Why the `<-chan` and `chan<-` syntax?

* `<-chan` → *receive-only channel* (worker can read from `requests` but not write)
* `chan<-` → *send-only channel* (worker can send to `results` but not read)

This helps **enforce channel direction**, making the code more readable and safe.

---

## 🚀 4. The main() function

### Step 1️⃣: Setup channels and variables

```go
numOfReqs := 5
price := 5
ticketRequests := make(chan ticketRequest, numOfReqs)
ticketResults := make(chan int)
```

* `numOfReqs` → total requests = 5.
* `price` → per-ticket price = ₹5.
* `ticketRequests` → buffered channel that holds incoming jobs.
* `ticketResults` → unbuffered channel for worker results.

---

### Step 2️⃣: Start the workers

```go
for range 3 {
	go ticketProcessor(ticketRequests, ticketResults)
}
```

⚠️ **This is slightly incorrect Go syntax.**
`for range 3` doesn’t compile because integers can’t be ranged over.

✅ Correct version:

```go
for i := 0; i < 3; i++ {
	go ticketProcessor(ticketRequests, ticketResults)
}
```

Now, **3 concurrent workers** start running the `ticketProcessor()` function — each waiting for incoming ticket requests.

---

### Step 3️⃣: Send ticket requests

```go
for i := range numOfReqs {
	ticketRequests <- ticketRequest{
		personId:     i + 1,
		numOfTickets: (i + 1) * 2,
		cost:         (i + 1) * price,
	}
}
close(ticketRequests)
```

⚠️ Same syntax issue — should be:

```go
for i := 0; i < numOfReqs; i++ {
	ticketRequests <- ticketRequest{
		personId:     i + 1,
		numOfTickets: (i + 1) * 2,
		cost:         (i + 1) * price,
	}
}
close(ticketRequests)
```

So we send **5 requests** like this:

| PersonID | Tickets | Cost |
| -------- | ------- | ---- |
| 1        | 2       | 5    |
| 2        | 4       | 10   |
| 3        | 6       | 15   |
| 4        | 8       | 20   |
| 5        | 10      | 25   |

Then we close the channel to tell workers “no more jobs are coming.”

---

### Step 4️⃣: Receive results

```go
for range numOfReqs {
	fmt.Printf("\n🟢Ticket for personId %d processed successfully", <-ticketResults)
}
```

This line blocks until it receives data from `ticketResults` 5 times — once per processed request.
The `<-ticketResults` reads whichever worker sends first.

That’s why **output order may vary** — the completion order depends on which worker finishes first.

---

## 🧾 5. Example Output Explained

```
Processing 2 ticket(s) of personId 1 with total cost of 5
Processing 4 ticket(s) of personId 2 with total cost of 10
Processing 6 ticket(s) of personId 3 with total cost of 15
Processing 8 ticket(s) of personId 4 with total cost of 20

🟢Ticket for personId 3 processed successfully
🟢Ticket for personId 1 processed successfully
🟢Ticket for personId 2 processed successfully
Processing 10 ticket(s) of personId 5 with total cost of 25

🟢Ticket for personId 4 processed successfully
🟢Ticket for personId 5 processed successfully
```

### What’s happening here:

1. **Three workers start together.**

   * Worker 1 takes request #1
   * Worker 2 takes request #2
   * Worker 3 takes request #3

2. Each sleeps for 1 second (simulated processing time).
   As soon as any finishes, it picks the next available request (#4, then #5).

3. The **order of completion** isn’t fixed — depends on how Go’s scheduler runs the goroutines.

   That’s why we see:

   * Processing order starts with 1, 2, 3, 4…
   * But success messages come out in mixed order (1, 3, 2, 4, 5, etc.)

✅ This randomness is **expected** and demonstrates true concurrency.

---

## 🧠 6. Why use Worker Pools?

Because:

* It **limits concurrency** — only 3 workers process at once (efficient resource usage).
* Prevents system overload (vs. creating a goroutine per task, which can be costly).
* Allows us to **reuse** goroutines for multiple jobs.
* Great for background processing, APIs, pipelines, file operations, etc.

---

## ✅ 7. Corrected & Clean Final Version

```go
package main

import (
	"fmt"
	"time"
)

type ticketRequest struct {
	personId     int
	numOfTickets int
	cost         int
}

func ticketProcessor(requests <-chan ticketRequest, results chan<- int) {
	for req := range requests {
		fmt.Printf("Processing %d ticket(s) of personId %d with total cost of %d\n",
			req.numOfTickets, req.personId, req.cost)
		time.Sleep(time.Second)
		results <- req.personId
	}
}

func main() {
	numOfReqs := 5
	price := 5
	ticketRequests := make(chan ticketRequest, numOfReqs)
	ticketResults := make(chan int, numOfReqs)

	// Create 3 workers
	for i := 0; i < 3; i++ {
		go ticketProcessor(ticketRequests, ticketResults)
	}

	// Send 5 ticket requests
	for i := 0; i < numOfReqs; i++ {
		ticketRequests <- ticketRequest{
			personId:     i + 1,
			numOfTickets: (i + 1) * 2,
			cost:         (i + 1) * price,
		}
	}
	close(ticketRequests)

	// Collect results
	for i := 0; i < numOfReqs; i++ {
		fmt.Printf("\n🟢 Ticket for personId %d processed successfully", <-ticketResults)
	}
}
```

---

## 🧩 8. Summary Table

| Concept                      | Meaning                                                    |
| ---------------------------- | ---------------------------------------------------------- |
| **Worker Pool**              | A fixed number of goroutines handle many jobs concurrently |
| **Channel**                  | Communication bridge between main and workers              |
| **Buffered Channel**         | Allows non-blocking sends until full                       |
| **Close(channel)**           | Signals “no more work”                                     |
| **time.Sleep()**             | Simulates long-running operations                          |
| **Non-deterministic output** | Workers finish in random order depending on scheduling     |

---

