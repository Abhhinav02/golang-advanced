# 1ï¸âƒ£ **TOKEN-BUCKET ALGORITHM** ğŸª£


```go 
package main

import (
	"fmt"
	"time"
)

// "Token Bucket Algorithm" implementation âš¡
// Why struct{}{} ? - No memory-overhead with an empty struct{} (0 bytes) ğŸ’¡

type RateLimiter struct {
	tokens     chan struct{}
	refillTime time.Duration
}

 func NewRateLimiter(rateLimit int, refillTime time.Duration) *RateLimiter{
	rl:= &RateLimiter{
	tokens: make(chan struct{}, rateLimit),
	refillTime: refillTime,
}
	for range rateLimit{
	rl.tokens <- struct{}{}
}
	go rl.startRefill() // goroutine running in the BG.
	return  rl
 }

 func (rl *RateLimiter) startRefill(){
	ticker:= time.NewTicker(rl.refillTime)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			select {
			case rl.tokens <-struct{}{}:
			default:
			}
		}
	}
} 

func (rl *RateLimiter) allow() bool{
	select {
	case <-rl.tokens:
		return true
	default:
		return false	
	}
}

func main() {
	rateLimiter:= NewRateLimiter(5,time.Second) // 5 requests

	// Let's send 10 requests
	for range 10{
		if rateLimiter.allow(){
			fmt.Println("Request Allowed âœ…")
		}else{
			fmt.Println("Request denied âŒ")
		}
		time.Sleep(200 * time.Millisecond) // some delay
	}

}

// OUTPUT: (200 ms. interval.. â±ï¸)
// $ go run .
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request denied âŒ
// Request denied âŒ
// Request denied âŒ
// Request denied âŒ
```

---
## ğŸ§  **Concept Recap: Token Bucket Algorithm**

* Itâ€™s a **rate-limiting algorithm** that controls how many operations (e.g., API requests) can happen per unit time.
* Think of it like a **bucket** that holds â€œtokens.â€
* Each token = 1 allowed request.
* When a request arrives:

  * If thereâ€™s a token â†’ take one out â†’ request allowed âœ…
  * If bucket empty â†’ request denied âŒ
* Tokens refill over time at a steady rate.

---

## âš™ï¸ **Our Code Walkthrough**

### 1ï¸âƒ£ Struct Definition

```go
type RateLimiter struct {
	tokens     chan struct{}
	refillTime time.Duration
}
```

* `tokens`: A **channel** of type `struct{}` used as the token bucket.

  * Why `struct{}{}`?

    * It takes **0 bytes** â€” memory-efficient.
    * We only care about the *count*, not data.
* `refillTime`: How often tokens refill.

---

### 2ï¸âƒ£ Constructor Function

```go
func NewRateLimiter(rateLimit int, refillTime time.Duration) *RateLimiter {
	rl := &RateLimiter{
		tokens: make(chan struct{}, rateLimit),
		refillTime: refillTime,
	}
	for range rateLimit {
		rl.tokens <- struct{}{}
	}
	go rl.startRefill()
	return rl
}
```

**Step-by-step:**

1. Creates a channel (`rl.tokens`) with buffer size = `rateLimit` (i.e., max tokens).
2. Fills the channel to capacity using:

   ```go
   for range rateLimit {
       rl.tokens <- struct{}{}
   }
   ```

   â†’ This simulates a **bucket initially full** of tokens.
3. Launches a **goroutine** `startRefill()` â†’ constantly refills tokens periodically.
4. Returns the new `RateLimiter` instance.

---

### 3ï¸âƒ£ Background Token Refill

```go
func (rl *RateLimiter) startRefill() {
	ticker := time.NewTicker(rl.refillTime)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			select {
			case rl.tokens <- struct{}{}:
			default:
			}
		}
	}
}
```

**Detailed breakdown:**

* `time.NewTicker(rl.refillTime)` creates a **ticker** that ticks every `refillTime`.
* Each tick triggers an attempt to **add a token** back into the bucket:

  ```go
  select {
  case rl.tokens <- struct{}{}:
  default:
  }
  ```

  * Inner `select` tries to send a token.
  * If the channel is already full (bucket full) â†’ `default` executes â†’ skip (no blocking).

âœ… **Key Point:**
This ensures the bucket *never overflows* â€” it stays capped at its maximum (`rateLimit`).

---

### 4ï¸âƒ£ Request Allow Function

```go
func (rl *RateLimiter) allow() bool {
	select {
	case <-rl.tokens:
		return true
	default:
		return false	
	}
}
```

* **Try to take a token** from the channel:

  * If available â†’ remove one â†’ request allowed âœ…
  * If empty â†’ skip `default` â†’ request denied âŒ
* The `select` with `default` makes it **non-blocking** â€” it immediately decides.

---

### 5ï¸âƒ£ Main Function

```go
func main() {
	rateLimiter := NewRateLimiter(5, time.Second) // 5 requests

	for range 10 {
		if rateLimiter.allow() {
			fmt.Println("Request Allowed âœ…")
		} else {
			fmt.Println("Request denied âŒ")
		}
		time.Sleep(200 * time.Millisecond)
	}
}
```

**Logic:**

* Bucket capacity = 5 tokens.
* Refill rate = 1 token per second.
* Loop sends 10 requests, every 200ms.

---

## ğŸ§© **Execution Timeline**

| Time (approx) | Request # | Tokens before   | Allowed? | Tokens after | Explanation          |
| ------------- | --------- | --------------- | -------- | ------------ | -------------------- |
| 0s            | 1         | 5               | âœ…        | 4            | Tokens available     |
| 0.2s          | 2         | 4               | âœ…        | 3            | Tokens available     |
| 0.4s          | 3         | 3               | âœ…        | 2            | Tokens available     |
| 0.6s          | 4         | 2               | âœ…        | 1            | Tokens available     |
| 0.8s          | 5         | 1               | âœ…        | 0            | Tokens available     |
| 1.0s          | 6         | 0 â†’ +1 (refill) | âœ…        | 0            | Refill happens at 1s |
| 1.2s          | 7         | 0               | âŒ        | 0            | No token yet         |
| 1.4s          | 8         | 0               | âŒ        | 0            | No token             |
| 1.6s          | 9         | 0               | âŒ        | 0            | No token             |
| 1.8s          | 10        | 0               | âŒ        | 0            | No token             |

Thatâ€™s why output shows **6 allowed** and **4 denied**.

---

## ğŸ§­ Summary

| Concept                 | Meaning                                |
| ----------------------- | -------------------------------------- |
| **Bucket capacity**     | `rateLimit` (5 tokens)                 |
| **Refill rate**         | 1 token every `refillTime`             |
| **Token channel**       | Represents available â€œpermitsâ€         |
| **Non-blocking select** | Prevents waiting on empty/full channel |
| **Refill goroutine**    | Keeps bucket topped up periodically    |

---

## ğŸ§© Real-World Analogy

Imagine a **parking lot** with 5 spaces:

* Each car (request) takes a space (token).
* Once full â†’ new cars wait outside (denied).
* Every few seconds, one car leaves (refill), freeing up a spot.

---

# 2ï¸âƒ£ **FIXED WINDOW ALGORITHM** ğŸªŸ

```go 
package main

import (
	"fmt"
	"sync"
	"time"
)

// "Fixed Window Counter" implementation âš¡
// Why mutex? - So that we can protect our data when we're modifying it (locking/unlocking the critical section).

type RateLimiter struct {
	mu sync.Mutex
	count int
	limit int
	window time.Duration
	resetTime time.Time
}

func NewRateLimiter(limit int, window time.Duration) *RateLimiter{
	return &RateLimiter{
		limit: limit,
		window: window,
	}
}

func (rl *RateLimiter) Allow()bool{
	rl.mu.Lock()
	defer rl.mu.Unlock()
	now:=time.Now()

	if now.After(rl.resetTime){
		rl.resetTime= now.Add(rl.window)
		rl.count = 0
	}

	if rl.count<rl.limit{
		rl.count++
		return true
	}
	return false
}

func main() {
	rateLimiter:= NewRateLimiter(5,2*time.Second) // 5 requests

	for range 10{
		if rateLimiter.Allow(){
			fmt.Println("Request Allowed âœ…")
		}else{
			fmt.Println("Request Denied âŒ")
		}
		time.Sleep(200 * time.Millisecond) // some delay
	}

}

// OUTPUT:
// $ go run .
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Allowed âœ…
// Request Denied âŒ
// Request Denied âŒ
// Request Denied âŒ
// Request Denied âŒ
// Request Denied âŒ
```
Letâ€™s **deep-dive into our Fixed Window Counter Go code** step by step.

---

# ğŸ§  **Overview: Fixed Window Counter Algorithm**

This code implements a **Fixed Window Rate Limiter**:

* Limits the number of requests that can occur in a **fixed time window**.
* Uses a **counter (`count`)** to track requests in the current window.
* Uses a **mutex** to prevent data races when accessed concurrently.
* If the counter exceeds the limit â†’ requests are denied until the window resets.

---

# âš™ï¸ **Code Walkthrough**

### 1ï¸âƒ£ Struct Definition

```go
type RateLimiter struct {
	mu sync.Mutex
	count int
	limit int
	window time.Duration
	resetTime time.Time
}
```

* `mu sync.Mutex` â†’ ensures **thread-safe access** to `count` and `resetTime`.
* `count` â†’ tracks how many requests have been made in the **current window**.
* `limit` â†’ max requests allowed in one window.
* `window` â†’ duration of the window (e.g., 2 seconds).
* `resetTime` â†’ timestamp when the **current window ends**.

---

### 2ï¸âƒ£ Constructor Function

```go
func NewRateLimiter(limit int, window time.Duration) *RateLimiter{
	return &RateLimiter{
		limit: limit,
		window: window,
	}
}
```

* Initializes a new rate limiter with a **request limit** and **window duration**.
* `resetTime` and `count` start at zero â€” window will be initialized on the first request.

---

### 3ï¸âƒ£ Core Logic â€” `Allow()`

```go
func (rl *RateLimiter) Allow() bool {
	rl.mu.Lock()
	defer rl.mu.Unlock()
	now := time.Now()

	if now.After(rl.resetTime) {
		rl.resetTime = now.Add(rl.window)
		rl.count = 0
	}

	if rl.count < rl.limit {
		rl.count++
		return true
	}
	return false
}
```

**Step-by-step:**

1. Lock the mutex â†’ critical section (ensures concurrent safety).
2. Get current time `now`.
3. **Check if window expired**:

   * If `now` is after `resetTime`, **reset the counter** to 0.
   * Update `resetTime` to `now + window`.
   * âœ… This starts a new fixed window.
4. **Check the limit**:

   * If `count < limit` â†’ increment count, allow request âœ…
   * Else â†’ deny request âŒ

---

### 4ï¸âƒ£ Main Function

```go
func main() {
	rateLimiter := NewRateLimiter(5, 2*time.Second) // 5 requests per 2s

	for range 10 {
		if rateLimiter.Allow() {
			fmt.Println("Request Allowed âœ…")
		} else {
			fmt.Println("Request Denied âŒ")
		}
		time.Sleep(200 * time.Millisecond)
	}
}
```

**Explanation:**

* Limit = 5 requests per 2 seconds
* Requests sent every 200ms (0.2s)
* Total 10 requests

---

# ğŸ•’ **Execution Timeline**

| Request # | Time (approx) | Window | Count Before | Allowed? | Count After | Notes         |
| --------- | ------------- | ------ | ------------ | -------- | ----------- | ------------- |
| 1         | 0.0s          | 0â€“2s   | 0            | âœ…        | 1           | First request |
| 2         | 0.2s          | 0â€“2s   | 1            | âœ…        | 2           | Within limit  |
| 3         | 0.4s          | 0â€“2s   | 2            | âœ…        | 3           | Within limit  |
| 4         | 0.6s          | 0â€“2s   | 3            | âœ…        | 4           | Within limit  |
| 5         | 0.8s          | 0â€“2s   | 4            | âœ…        | 5           | Reaches limit |
| 6         | 1.0s          | 0â€“2s   | 5            | âŒ        | 5           | Limit reached |
| 7         | 1.2s          | 0â€“2s   | 5            | âŒ        | 5           | Denied        |
| 8         | 1.4s          | 0â€“2s   | 5            | âŒ        | 5           | Denied        |
| 9         | 1.6s          | 0â€“2s   | 5            | âŒ        | 5           | Denied        |
| 10        | 1.8s          | 0â€“2s   | 5            | âŒ        | 5           | Denied        |

âœ… Output matches your observed results:

```
Request Allowed âœ…
Request Allowed âœ…
Request Allowed âœ…
Request Allowed âœ…
Request Allowed âœ…
Request Denied âŒ
Request Denied âŒ
Request Denied âŒ
Request Denied âŒ
Request Denied âŒ
```

---

# ğŸ§  **Key Concepts Illustrated**

1. **Fixed Window Counter**:

   * Simple counter + time window.
   * Resets at the **end of each window**.

2. **Mutex (`sync.Mutex`)**:

   * Protects `count` and `resetTime` from **data races** if multiple goroutines call `Allow()`.

3. **Burstiness Issue**:

   * All 5 allowed requests can happen at the **end of one window**, and 5 more at the **start of the next window**, causing **bursts**.
   * This is a known limitation of the fixed window algorithm.

4. **Non-blocking**:

   * `Allow()` returns **true/false immediately**.
   * No queuing or waiting.

---

# ğŸ§© **Summary Table**

| Feature           | Implementation in this code               |
| ----------------- | ----------------------------------------- |
| Window Type       | Fixed window                              |
| Counter           | `count` tracks requests in current window |
| Limit             | `limit`                                   |
| Window Size       | `window`                                  |
| Reset             | `resetTime` checked on each `Allow()`     |
| Concurrency Safe? | Yes, via `sync.Mutex`                     |
| Drawback          | Can allow burst at window boundaries      |

---

This is the **classic fixed-window rate limiter** â€” very simple and easy to implement, but not perfect for smoothing traffic.

---

Letâ€™s visualize your **Fixed Window Rate Limiter** with a timeline diagram. This will make the allowed/denied requests much clearer.

---

# â±ï¸ **Timeline Diagram â€” Fixed Window**

**Settings from your code:**

* Limit = 5 requests per 2 seconds
* Requests every 0.2s
* Total requests = 10

```
Time (s): 0   0.2   0.4   0.6   0.8   1.0   1.2   1.4   1.6   1.8
Request #: 1    2     3     4     5     6     7     8     9     10

Window 0â€“2s:
Allowed:  âœ…   âœ…    âœ…    âœ…    âœ…  
Denied:                                     âŒ    âŒ    âŒ    âŒ    âŒ

Window resets at 2s:
Next allowed requests would start from count = 0
```

---

### ğŸŸ¢ **Explanation**

1. **Window 0â€“2s**

   * Requests 1â€“5 â†’ counter < limit â†’ **allowed** âœ…
   * Requests 6â€“10 â†’ counter = limit â†’ **denied** âŒ

2. **After 2s**

   * `resetTime` updates â†’ `count` resets to 0
   * Next batch of requests would again be allowed up to the limit

---

### ğŸ”¹ **Visual Representation**

```
[Window 0-2s]  
Req#1 âœ…  Req#2 âœ…  Req#3 âœ…  Req#4 âœ…  Req#5 âœ…  Req#6 âŒ  Req#7 âŒ  Req#8 âŒ  Req#9 âŒ  Req#10 âŒ
```

**Key Observations:**

* **All allowed requests happen first**, then all denials â€” classic **fixed-window burstiness**.
* If we had requests **straddling two windows**, the limiter would reset exactly at `2s` and start allowing again.

---

### âš¡ **Burstiness Problem (Optional Note)**

If requests were made like this:

```
Request 1-5: at 1.9s â†’ allowed (end of previous window)
Request 6-10: at 2.1s â†’ allowed (start of new window)
```

Then **10 requests could happen in just 0.2s**, even though limit = 5 per 2s.

This is why **Sliding Window or Token Bucket** is preferred for smoother control.

---
![alt text](image.png)

