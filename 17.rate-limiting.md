# 1️⃣ **TOKEN-BUCKET ALGORITHM** 🪣


```go 
package main

import (
	"fmt"
	"time"
)

// "Token Bucket Algorithm" implementation ⚡
// Why struct{}{} ? - No memory-overhead with an empty struct{} (0 bytes) 💡

type RateLimiter struct {
	tokens     chan struct{}
	refillTime time.Duration
}

 func NewRateLimiter(rateLimit int, refillTime time.Duration) *RateLimiter{
	rl:= &RateLimiter{
	tokens: make(chan struct{}, rateLimit),
	refillTime: refillTime,
}
	for range rateLimit{
	rl.tokens <- struct{}{}
}
	go rl.startRefill() // goroutine running in the BG.
	return  rl
 }

 func (rl *RateLimiter) startRefill(){
	ticker:= time.NewTicker(rl.refillTime)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			select {
			case rl.tokens <-struct{}{}:
			default:
			}
		}
	}
} 

func (rl *RateLimiter) allow() bool{
	select {
	case <-rl.tokens:
		return true
	default:
		return false	
	}
}

func main() {
	rateLimiter:= NewRateLimiter(5,time.Second) // 5 requests

	// Let's send 10 requests
	for range 10{
		if rateLimiter.allow(){
			fmt.Println("Request Allowed ✅")
		}else{
			fmt.Println("Request denied ❌")
		}
		time.Sleep(200 * time.Millisecond) // some delay
	}

}

// OUTPUT: (200 ms. interval.. ⏱️)
// $ go run .
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request denied ❌
// Request denied ❌
// Request denied ❌
// Request denied ❌
```

---
## 🧠 **Concept Recap: Token Bucket Algorithm**

* It’s a **rate-limiting algorithm** that controls how many operations (e.g., API requests) can happen per unit time.
* Think of it like a **bucket** that holds “tokens.”
* Each token = 1 allowed request.
* When a request arrives:

  * If there’s a token → take one out → request allowed ✅
  * If bucket empty → request denied ❌
* Tokens refill over time at a steady rate.

---

## ⚙️ **Our Code Walkthrough**

### 1️⃣ Struct Definition

```go
type RateLimiter struct {
	tokens     chan struct{}
	refillTime time.Duration
}
```

* `tokens`: A **channel** of type `struct{}` used as the token bucket.

  * Why `struct{}{}`?

    * It takes **0 bytes** — memory-efficient.
    * We only care about the *count*, not data.
* `refillTime`: How often tokens refill.

---

### 2️⃣ Constructor Function

```go
func NewRateLimiter(rateLimit int, refillTime time.Duration) *RateLimiter {
	rl := &RateLimiter{
		tokens: make(chan struct{}, rateLimit),
		refillTime: refillTime,
	}
	for range rateLimit {
		rl.tokens <- struct{}{}
	}
	go rl.startRefill()
	return rl
}
```

**Step-by-step:**

1. Creates a channel (`rl.tokens`) with buffer size = `rateLimit` (i.e., max tokens).
2. Fills the channel to capacity using:

   ```go
   for range rateLimit {
       rl.tokens <- struct{}{}
   }
   ```

   → This simulates a **bucket initially full** of tokens.
3. Launches a **goroutine** `startRefill()` → constantly refills tokens periodically.
4. Returns the new `RateLimiter` instance.

---

### 3️⃣ Background Token Refill

```go
func (rl *RateLimiter) startRefill() {
	ticker := time.NewTicker(rl.refillTime)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			select {
			case rl.tokens <- struct{}{}:
			default:
			}
		}
	}
}
```

**Detailed breakdown:**

* `time.NewTicker(rl.refillTime)` creates a **ticker** that ticks every `refillTime`.
* Each tick triggers an attempt to **add a token** back into the bucket:

  ```go
  select {
  case rl.tokens <- struct{}{}:
  default:
  }
  ```

  * Inner `select` tries to send a token.
  * If the channel is already full (bucket full) → `default` executes → skip (no blocking).

✅ **Key Point:**
This ensures the bucket *never overflows* — it stays capped at its maximum (`rateLimit`).

---

### 4️⃣ Request Allow Function

```go
func (rl *RateLimiter) allow() bool {
	select {
	case <-rl.tokens:
		return true
	default:
		return false	
	}
}
```

* **Try to take a token** from the channel:

  * If available → remove one → request allowed ✅
  * If empty → skip `default` → request denied ❌
* The `select` with `default` makes it **non-blocking** — it immediately decides.

---

### 5️⃣ Main Function

```go
func main() {
	rateLimiter := NewRateLimiter(5, time.Second) // 5 requests

	for range 10 {
		if rateLimiter.allow() {
			fmt.Println("Request Allowed ✅")
		} else {
			fmt.Println("Request denied ❌")
		}
		time.Sleep(200 * time.Millisecond)
	}
}
```

**Logic:**

* Bucket capacity = 5 tokens.
* Refill rate = 1 token per second.
* Loop sends 10 requests, every 200ms.

---

## 🧩 **Execution Timeline**

| Time (approx) | Request # | Tokens before   | Allowed? | Tokens after | Explanation          |
| ------------- | --------- | --------------- | -------- | ------------ | -------------------- |
| 0s            | 1         | 5               | ✅        | 4            | Tokens available     |
| 0.2s          | 2         | 4               | ✅        | 3            | Tokens available     |
| 0.4s          | 3         | 3               | ✅        | 2            | Tokens available     |
| 0.6s          | 4         | 2               | ✅        | 1            | Tokens available     |
| 0.8s          | 5         | 1               | ✅        | 0            | Tokens available     |
| 1.0s          | 6         | 0 → +1 (refill) | ✅        | 0            | Refill happens at 1s |
| 1.2s          | 7         | 0               | ❌        | 0            | No token yet         |
| 1.4s          | 8         | 0               | ❌        | 0            | No token             |
| 1.6s          | 9         | 0               | ❌        | 0            | No token             |
| 1.8s          | 10        | 0               | ❌        | 0            | No token             |

That’s why output shows **6 allowed** and **4 denied**.

---

## 🧭 Summary

| Concept                 | Meaning                                |
| ----------------------- | -------------------------------------- |
| **Bucket capacity**     | `rateLimit` (5 tokens)                 |
| **Refill rate**         | 1 token every `refillTime`             |
| **Token channel**       | Represents available “permits”         |
| **Non-blocking select** | Prevents waiting on empty/full channel |
| **Refill goroutine**    | Keeps bucket topped up periodically    |

---

## 🧩 Real-World Analogy

Imagine a **parking lot** with 5 spaces:

* Each car (request) takes a space (token).
* Once full → new cars wait outside (denied).
* Every few seconds, one car leaves (refill), freeing up a spot.

---

# 2️⃣ **FIXED WINDOW ALGORITHM** 🪟

```go 
package main

import (
	"fmt"
	"sync"
	"time"
)

// "Fixed Window Counter" implementation ⚡
// Why mutex? - So that we can protect our data when we're modifying it (locking/unlocking the critical section).

type RateLimiter struct {
	mu sync.Mutex
	count int
	limit int
	window time.Duration
	resetTime time.Time
}

func NewRateLimiter(limit int, window time.Duration) *RateLimiter{
	return &RateLimiter{
		limit: limit,
		window: window,
	}
}

func (rl *RateLimiter) Allow()bool{
	rl.mu.Lock()
	defer rl.mu.Unlock()
	now:=time.Now()

	if now.After(rl.resetTime){
		rl.resetTime= now.Add(rl.window)
		rl.count = 0
	}

	if rl.count<rl.limit{
		rl.count++
		return true
	}
	return false
}

func main() {
	rateLimiter:= NewRateLimiter(5,2*time.Second) // 5 requests

	for range 10{
		if rateLimiter.Allow(){
			fmt.Println("Request Allowed ✅")
		}else{
			fmt.Println("Request Denied ❌")
		}
		time.Sleep(200 * time.Millisecond) // some delay
	}

}

// OUTPUT:
// $ go run .
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Allowed ✅
// Request Denied ❌
// Request Denied ❌
// Request Denied ❌
// Request Denied ❌
// Request Denied ❌
```
Let’s **deep-dive into our Fixed Window Counter Go code** step by step.

---

# 🧠 **Overview: Fixed Window Counter Algorithm**

This code implements a **Fixed Window Rate Limiter**:

* Limits the number of requests that can occur in a **fixed time window**.
* Uses a **counter (`count`)** to track requests in the current window.
* Uses a **mutex** to prevent data races when accessed concurrently.
* If the counter exceeds the limit → requests are denied until the window resets.

---

# ⚙️ **Code Walkthrough**

### 1️⃣ Struct Definition

```go
type RateLimiter struct {
	mu sync.Mutex
	count int
	limit int
	window time.Duration
	resetTime time.Time
}
```

* `mu sync.Mutex` → ensures **thread-safe access** to `count` and `resetTime`.
* `count` → tracks how many requests have been made in the **current window**.
* `limit` → max requests allowed in one window.
* `window` → duration of the window (e.g., 2 seconds).
* `resetTime` → timestamp when the **current window ends**.

---

### 2️⃣ Constructor Function

```go
func NewRateLimiter(limit int, window time.Duration) *RateLimiter{
	return &RateLimiter{
		limit: limit,
		window: window,
	}
}
```

* Initializes a new rate limiter with a **request limit** and **window duration**.
* `resetTime` and `count` start at zero — window will be initialized on the first request.

---

### 3️⃣ Core Logic — `Allow()`

```go
func (rl *RateLimiter) Allow() bool {
	rl.mu.Lock()
	defer rl.mu.Unlock()
	now := time.Now()

	if now.After(rl.resetTime) {
		rl.resetTime = now.Add(rl.window)
		rl.count = 0
	}

	if rl.count < rl.limit {
		rl.count++
		return true
	}
	return false
}
```

**Step-by-step:**

1. Lock the mutex → critical section (ensures concurrent safety).
2. Get current time `now`.
3. **Check if window expired**:

   * If `now` is after `resetTime`, **reset the counter** to 0.
   * Update `resetTime` to `now + window`.
   * ✅ This starts a new fixed window.
4. **Check the limit**:

   * If `count < limit` → increment count, allow request ✅
   * Else → deny request ❌

---

### 4️⃣ Main Function

```go
func main() {
	rateLimiter := NewRateLimiter(5, 2*time.Second) // 5 requests per 2s

	for range 10 {
		if rateLimiter.Allow() {
			fmt.Println("Request Allowed ✅")
		} else {
			fmt.Println("Request Denied ❌")
		}
		time.Sleep(200 * time.Millisecond)
	}
}
```

**Explanation:**

* Limit = 5 requests per 2 seconds
* Requests sent every 200ms (0.2s)
* Total 10 requests

---

# 🕒 **Execution Timeline**

| Request # | Time (approx) | Window | Count Before | Allowed? | Count After | Notes         |
| --------- | ------------- | ------ | ------------ | -------- | ----------- | ------------- |
| 1         | 0.0s          | 0–2s   | 0            | ✅        | 1           | First request |
| 2         | 0.2s          | 0–2s   | 1            | ✅        | 2           | Within limit  |
| 3         | 0.4s          | 0–2s   | 2            | ✅        | 3           | Within limit  |
| 4         | 0.6s          | 0–2s   | 3            | ✅        | 4           | Within limit  |
| 5         | 0.8s          | 0–2s   | 4            | ✅        | 5           | Reaches limit |
| 6         | 1.0s          | 0–2s   | 5            | ❌        | 5           | Limit reached |
| 7         | 1.2s          | 0–2s   | 5            | ❌        | 5           | Denied        |
| 8         | 1.4s          | 0–2s   | 5            | ❌        | 5           | Denied        |
| 9         | 1.6s          | 0–2s   | 5            | ❌        | 5           | Denied        |
| 10        | 1.8s          | 0–2s   | 5            | ❌        | 5           | Denied        |

✅ Output matches your observed results:

```
Request Allowed ✅
Request Allowed ✅
Request Allowed ✅
Request Allowed ✅
Request Allowed ✅
Request Denied ❌
Request Denied ❌
Request Denied ❌
Request Denied ❌
Request Denied ❌
```

---

# 🧠 **Key Concepts Illustrated**

1. **Fixed Window Counter**:

   * Simple counter + time window.
   * Resets at the **end of each window**.

2. **Mutex (`sync.Mutex`)**:

   * Protects `count` and `resetTime` from **data races** if multiple goroutines call `Allow()`.

3. **Burstiness Issue**:

   * All 5 allowed requests can happen at the **end of one window**, and 5 more at the **start of the next window**, causing **bursts**.
   * This is a known limitation of the fixed window algorithm.

4. **Non-blocking**:

   * `Allow()` returns **true/false immediately**.
   * No queuing or waiting.

---

# 🧩 **Summary Table**

| Feature           | Implementation in this code               |
| ----------------- | ----------------------------------------- |
| Window Type       | Fixed window                              |
| Counter           | `count` tracks requests in current window |
| Limit             | `limit`                                   |
| Window Size       | `window`                                  |
| Reset             | `resetTime` checked on each `Allow()`     |
| Concurrency Safe? | Yes, via `sync.Mutex`                     |
| Drawback          | Can allow burst at window boundaries      |

---

This is the **classic fixed-window rate limiter** — very simple and easy to implement, but not perfect for smoothing traffic.

---

Let’s visualize your **Fixed Window Rate Limiter** with a timeline diagram. This will make the allowed/denied requests much clearer.

---

# ⏱️ **Timeline Diagram — Fixed Window**

**Settings from your code:**

* Limit = 5 requests per 2 seconds
* Requests every 0.2s
* Total requests = 10

```
Time (s): 0   0.2   0.4   0.6   0.8   1.0   1.2   1.4   1.6   1.8
Request #: 1    2     3     4     5     6     7     8     9     10

Window 0–2s:
Allowed:  ✅   ✅    ✅    ✅    ✅  
Denied:                                     ❌    ❌    ❌    ❌    ❌

Window resets at 2s:
Next allowed requests would start from count = 0
```

---

### 🟢 **Explanation**

1. **Window 0–2s**

   * Requests 1–5 → counter < limit → **allowed** ✅
   * Requests 6–10 → counter = limit → **denied** ❌

2. **After 2s**

   * `resetTime` updates → `count` resets to 0
   * Next batch of requests would again be allowed up to the limit

---

### 🔹 **Visual Representation**

```
[Window 0-2s]  
Req#1 ✅  Req#2 ✅  Req#3 ✅  Req#4 ✅  Req#5 ✅  Req#6 ❌  Req#7 ❌  Req#8 ❌  Req#9 ❌  Req#10 ❌
```

**Key Observations:**

* **All allowed requests happen first**, then all denials — classic **fixed-window burstiness**.
* If we had requests **straddling two windows**, the limiter would reset exactly at `2s` and start allowing again.

---

### ⚡ **Burstiness Problem (Optional Note)**

If requests were made like this:

```
Request 1-5: at 1.9s → allowed (end of previous window)
Request 6-10: at 2.1s → allowed (start of new window)
```

Then **10 requests could happen in just 0.2s**, even though limit = 5 per 2s.

This is why **Sliding Window or Token Bucket** is preferred for smoother control.

---
![alt text](image.png)

