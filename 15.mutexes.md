1Ô∏è‚É£ **MUTEX EXECUTION** ‚ö°

Let‚Äôs walk through **the following code**, **line by line**..

---

```go 
package main

import (
	"fmt"
	"sync"
)

/*
üí°mutexes - mitual exclution, sync. primitive which prevents multiple goroutines from simultaneously accessing shared resources or exeuting critical sections of the code. Ensures that only 1 goroutine can hold the 'mutex' at a time, thus avaoiding race-conditions and data-corruption. üíª
*/

type Counter struct{
	mu sync.Mutex
	val int
}

func (c *Counter)increment(){
	c.mu.Lock()
	c.val++
	defer c.mu.Unlock()
}

func (c *Counter) getVal()int{
	c.mu.Lock()
	defer c.mu.Unlock()
	return c.val
}

func main() {
	// waitgroups for multiple goroutines
	var wg sync.WaitGroup
	counter:= &Counter{}
	numOfGoroutines := 10

	for range numOfGoroutines{
		wg.Add(1)
		go func() {
			defer wg.Done()
			for range 100{
				counter.increment()
			}
		}()
	}
	wg.Wait()
	fmt.Printf("‚úÖ Final counter val: %d\n",counter.getVal()) // ‚ö†Ô∏èunreliable output without 'mutex'

	// O.P- 
	// $ go run .
	// ‚úÖ Final counter val: 1000
}
```

### üß† Step-by-step Breakdown

---

#### **Imports**

```go
import (
	"fmt"
	"sync"
)
```

We‚Äôre importing:

* `fmt` ‚Üí for printing output to the console.
* `sync` ‚Üí which gives us synchronization primitives like `Mutex` and `WaitGroup` for managing concurrency safely.

---

#### **Comment Block**

```go
/*
mutexes - mitual exclution, sync. primitive which prevents multiple goroutines from simultaneously accessing shared resources or exeuting critical sections of the code. Ensures that only 1 goroutine can hold the 'mutex' at a time, thus avaoiding race-conditions and data-corruption. üíª
*/
```

That‚Äôs a perfect conceptual description already:
üëâ A **mutex (mutual exclusion lock)** ensures that only **one goroutine** can access a critical section (shared resource) at any given time.
This prevents **race conditions** ‚Äî situations where multiple goroutines try to read and write to the same variable concurrently, leading to unpredictable results.

---

#### **Struct Definition**

```go
type Counter struct{
	mu sync.Mutex
	val int
}
```

We define a struct named `Counter` that contains:

* `mu`: a **mutex** to control concurrent access.
* `val`: an integer counter we want to update safely from multiple goroutines.

Think of the mutex as a **lock on a door** ‚Äî only one goroutine can enter (modify `val`) at a time.

---

#### **increment() method**

```go
func (c *Counter)increment(){
	c.mu.Lock()
	c.val++
	defer c.mu.Unlock()
}
```

This method increments the counter.

Let‚Äôs go line-by-line inside it:

1. **`c.mu.Lock()`**

   * This locks the mutex.
   * If another goroutine already holds the lock, this goroutine will **wait (block)** until the mutex is unlocked.
   * Once it obtains the lock, it enters the critical section (safe area to modify `val`).

2. **`c.val++`**

   * This is the critical section.
   * `val++` is *not* an atomic operation ‚Äî it actually does three things internally:

     ```
     temp = c.val
     temp = temp + 1
     c.val = temp
     ```

     So if multiple goroutines did this at the same time without a mutex, they‚Äôd overwrite each other‚Äôs updates ‚Äî that‚Äôs the classic race condition.

3. **`defer c.mu.Unlock()`**

   * The `defer` schedules the unlock to run *after the function finishes*.
   * In Go, deferred calls run in **LIFO order** just before the function returns.
   * So when `increment()` ends, the mutex automatically unlocks ‚Äî allowing another goroutine to acquire it and safely increment again.

üü° **Note:** Normally, we place `defer c.mu.Unlock()` *right after* `Lock()` to guarantee unlock even if something panics before the increment.
But since `c.val++` here can‚Äôt panic, it still works ‚Äî just not the most idiomatic placement.

---

#### **getVal() method**

```go
func (c *Counter) getVal()int{
	c.mu.Lock()
	defer c.mu.Unlock()
	return c.val
}
```

This method safely reads the counter‚Äôs value.

* It locks before reading `c.val` (to ensure we‚Äôre not reading while another goroutine is writing).
* It defers unlock immediately (idiomatic).
* It returns the counter value once the lock is released.

So even reading is synchronized ‚Äî preventing data races between read/write.

---

#### **main() function**

```go
func main() {
	// waitgroups for multiple goroutines
	var wg sync.WaitGroup
	counter:= &Counter{}
	numOfGoroutines := 10
```

Here:

* `wg` ‚Üí a `WaitGroup` to track and wait for multiple goroutines to finish.
* `counter` ‚Üí a pointer to a `Counter` instance (we use a pointer so we don‚Äôt accidentally copy the mutex).
* `numOfGoroutines := 10` ‚Üí we‚Äôll spawn 10 goroutines to increment the counter concurrently.

---

#### **Launching Goroutines**

```go
	for range numOfGoroutines{
		wg.Add(1)
		go func() {
			defer wg.Done()
			for range 100{
				counter.increment()
			}
		}()
	}
```

Even though `for range numOfGoroutines` and `for range 100` wouldn‚Äôt compile in Go (you‚Äôd normally write `for i := 0; i < numOfGoroutines; i++`), let‚Äôs **conceptually** understand what this loop is *intended* to do:

* The loop runs **10 times**, creating 10 goroutines.
* Each goroutine:

  * Calls `defer wg.Done()` ‚Üí meaning when that goroutine finishes, it signals the WaitGroup that one job is done.
  * Runs another loop **100 times**, calling `counter.increment()` each time.

So effectively:

```
10 goroutines √ó 100 increments each = 1000 total increments
```

Each call to `increment()` locks the mutex, increments safely, and unlocks, one at a time.

This creates **serialized access** to the shared counter.

---

#### **Wait for Completion**

```go
	wg.Wait()
```

The main goroutine blocks here until all 10 goroutines have called `wg.Done()` (i.e., finished their 100 increments each).

Once all have finished ‚Üí `wg.Wait()` unblocks.

---

#### **Final Print**

```go
	fmt.Printf("‚úÖ Final counter val: %d\n",counter.getVal()) // unreliable output without 'mutex'
```

Finally, we print the counter value.

If mutexes were missing:

* The increments would overlap (race conditions).
* The result would be random and **less than 1000** most of the time.

But since we used the mutex correctly, the result is always:

```
‚úÖ Final counter val: 1000
```

---

### üîç Why it works perfectly

1. Only one goroutine modifies `c.val` at any given moment.
2. The mutex ensures mutual exclusion.
3. The WaitGroup ensures synchronization ‚Äî we don‚Äôt print before work finishes.
4. The final print happens after all increments are complete.

Hence, the output is deterministic and correct.

---

### ‚öôÔ∏è Under the Hood

Let‚Äôs visualize what‚Äôs happening during execution:

```
Goroutine-1 locks -> increments -> unlocks
Goroutine-2 locks -> increments -> unlocks
Goroutine-3 locks -> increments -> unlocks
...
```

Each goroutine tries to acquire the lock. If it‚Äôs taken, it waits.
Once the lock is free, it grabs it, increments, defers the unlock, and releases it ‚Äî giving the next goroutine a chance.

This sequence happens very fast, so effectively the counter increments appear atomic.

---

### üß© Summary Table

| Concept          | Purpose                                                                    |
| ---------------- | -------------------------------------------------------------------------- |
| `sync.Mutex`     | Prevents multiple goroutines from entering critical section simultaneously |
| `Lock()`         | Acquire the mutex (waits if already locked)                                |
| `Unlock()`       | Releases the mutex                                                         |
| `defer Unlock()` | Ensures unlock always happens when function exits                          |
| `sync.WaitGroup` | Waits until all goroutines finish                                          |
| `wg.Add(n)`      | Tells how many goroutines to wait for                                      |
| `wg.Done()`      | Decrements the counter                                                     |
| `wg.Wait()`      | Blocks until counter hits zero                                             |
| `c.val++`        | Shared data safely modified under lock                                     |
| Final result     | Always `1000` (since 10 √ó 100 increments)                                  |

---

### üß† TL;DR

Your code demonstrates **safe concurrent access** to a shared variable using:

* `sync.Mutex` ‚Üí to ensure **mutual exclusion**.
* `sync.WaitGroup` ‚Üí to ensure **completion synchronization**.

Each goroutine safely increments the counter 100 times, producing a predictable final output:

```
‚úÖ Final counter val: 1000
```
---

Alright let‚Äôs go through **the exact code** line by line, as it is, **without changing anything**, and deeply understand what‚Äôs going on under the hood.

---

### üß± Code Overview

```go
package main

import (
	"fmt"
	"sync"
)
```

We‚Äôre importing:

* **fmt** ‚Üí for printing output
* **sync** ‚Üí for synchronization primitives like `Mutex` and `WaitGroup`

---

### üîí Step 1: The `Counter` struct

```go
type Counter struct {
	mu  sync.Mutex
	val int
}
```

* `mu` ‚Üí a **mutex** that ensures mutual exclusion.
* `val` ‚Üí our **shared resource** (the counter value) that multiple goroutines will modify.

The mutex ensures that **only one goroutine at a time** can access/modify `val`.

---

### ‚öôÔ∏è Step 2: `increment` method

```go
func (c *Counter) increment() {
	c.mu.Lock()
	c.val++
	defer c.mu.Unlock()
}
```

Let‚Äôs unpack this carefully:

1. `c.mu.Lock()` ‚Üí acquires the **lock**.

   * If another goroutine already holds the lock, this goroutine will **block** (pause) until the lock is released.

2. `c.val++` ‚Üí increments the shared counter.

3. `defer c.mu.Unlock()` ‚Üí schedules unlocking once the function returns.

> üí° Even though the `defer` line appears **after** `c.val++`, it‚Äôs still **registered immediately** when that line executes.
> So, `Unlock()` will happen when `increment()` finishes.

In effect, for each goroutine:

* It **locks**, increments safely, and **then unlocks** before another goroutine can enter this critical section.

---

### üîç Step 3: `getVal` method

```go
func (c *Counter) getVal() int {
	c.mu.Lock()
	defer c.mu.Unlock()
	return c.val
}
```

This function also locks the mutex before reading the shared value.
That ensures we don‚Äôt read it while another goroutine might be writing to it ‚Äî preventing **race conditions** during read operations.

---

### üë∑ Step 4: Inside `main()`

```go
var wg sync.WaitGroup
counter := &Counter{}
numOfGoroutines := 10
```

* We create a **WaitGroup** to wait for all goroutines to finish.
* We create a shared **counter** instance (pointer so that all goroutines access the same one).
* We‚Äôll run **10 goroutines** to increment it concurrently.

---

### üöÄ Step 5: Spawning goroutines

```go
for range numOfGoroutines {
	wg.Add(1)
	go func() {
		defer wg.Done()
		for range 100 {
			counter.increment()
		}
	}()
}
```

Let‚Äôs decode this loop:

1. `for range numOfGoroutines`

   * Runs 10 times because `numOfGoroutines` is `10`.

2. Each iteration:

   * Adds 1 to the WaitGroup (`wg.Add(1)`).
   * Launches a **new goroutine** ‚Äî an independent lightweight thread of execution.

3. Inside each goroutine:

   * `defer wg.Done()` ensures that when it finishes, it signals the main goroutine that it‚Äôs done.
   * The inner `for range 100` loop runs 100 times, incrementing the counter 100 times **safely**.

So, in total:

```
10 goroutines √ó 100 increments each = 1000 increments total
```

---

### üïí Step 6: Waiting for all goroutines

```go
wg.Wait()
```

* The main goroutine waits here until **all 10 goroutines** have called `wg.Done()`.
* This ensures all increments complete before we move to print the final value.

---

### üßÆ Step 7: Printing the final result

```go
fmt.Printf("‚úÖ Final counter val: %d\n", counter.getVal())
```

At this point:

* All goroutines are finished.
* The mutex guarantees no race conditions.
* The final value of the counter = **1000** (10 √ó 100).

---

### ‚úÖ Output

```
‚úÖ Final counter val: 1000
```

---

### üß† Why mutex is essential here

Without the mutex, multiple goroutines could execute `c.val++` simultaneously.
This looks innocent, but it‚Äôs not atomic ‚Äî under the hood, it‚Äôs equivalent to:

```go
temp := c.val   // read
temp = temp + 1 // increment
c.val = temp    // write
```

If two goroutines do this at once, one‚Äôs write could **overwrite** another‚Äôs result, leading to a smaller final count (e.g., 967, 984, etc.).

The mutex ensures these three steps happen **as one atomic block** ‚Äî no interruptions.

---

### üß© Summary Table

| Step                | Operation | Protected by Mutex?          | Notes |
| ------------------- | --------- | ---------------------------- | ----- |
| Increment (`val++`) | ‚úÖ         | Prevents race condition      |       |
| Read (`getVal()`)   | ‚úÖ         | Ensures consistent read      |       |
| Concurrent access   | ‚úÖ         | Only one goroutine at a time |       |
| Final output        | `1000`    | Always correct               |       |

---

### üß≠ Real-world analogy

Think of the mutex as a **key to a single restroom** üöª:

* Only one person (goroutine) can enter at a time.
* Everyone else must wait until the key is returned (Unlock).
* Once done, the next in line can safely go in.

---

Perfect,  üî• let‚Äôs now see **exactly what goes wrong** when we remove the mutex and why the final value becomes unreliable.
We‚Äôll use our same code, but comment out the mutex parts so we can clearly see the difference in behavior.

---

## ‚ö†Ô∏è 1Ô∏è‚É£ Version WITHOUT Mutex

```go
package main

import (
	"fmt"
	"sync"
)

type Counter struct {
	val int
}

func (c *Counter) increment() {
	// ‚ùå No mutex protection
	c.val++
}

func (c *Counter) getVal() int {
	return c.val
}

func main() {
	var wg sync.WaitGroup
	counter := &Counter{}
	numOfGoroutines := 10

	for range numOfGoroutines {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for range 100 {
				counter.increment()
			}
		}()
	}

	wg.Wait()
	fmt.Printf("‚ö†Ô∏è Final counter val (no mutex): %d\n", counter.getVal())
}
```

---

## üß† Expected output (if perfectly serialized)

If everything ran in perfect sequence, we‚Äôd expect:

```
10 goroutines √ó 100 increments = 1000
```

So, the final value **should** be `1000`.

---

## üòà Actual output (race condition at play)

Run this several times, and you‚Äôll likely see outputs like:

```
‚ö†Ô∏è Final counter val (no mutex): 973
‚ö†Ô∏è Final counter val (no mutex): 991
‚ö†Ô∏è Final counter val (no mutex): 985
‚ö†Ô∏è Final counter val (no mutex): 1000
‚ö†Ô∏è Final counter val (no mutex): 968
```

The number changes **randomly** on each run.
That randomness is the result of **race conditions**.

---

## üîç Why race conditions occur

Let‚Äôs zoom into the line:

```go
c.val++
```

This looks atomic but it‚Äôs **actually three CPU-level operations**:

1. **Read** the current value of `c.val` from memory into a register.
2. **Add 1** to it.
3. **Write** the new value back to memory.

Now imagine two goroutines (G1, G2) running in parallel on different CPU cores:

| Step | G1                | G2                | Result             |
| ---- | ----------------- | ----------------- | ------------------ |
| 1Ô∏è‚É£  | Reads `c.val = 5` | ‚Äî                 | ‚Äî                  |
| 2Ô∏è‚É£  | ‚Äî                 | Reads `c.val = 5` | ‚Äî                  |
| 3Ô∏è‚É£  | Increments ‚Üí `6`  | Increments ‚Üí `6`  | ‚ùå One update lost! |

Each thinks it incremented `5 ‚Üí 6`, but both wrote `6`.
So, one increment **overwrites** the other ‚Äî a classic race condition.

---

## üïµÔ∏è‚Äç‚ôÇÔ∏è Detecting it with Go‚Äôs race detector

Go actually comes with a built-in **race detector**.
Try running your code with:

```
go run -race .
```

Output example:

```
==================
WARNING: DATA RACE
Read at 0x00c0000a6010 by goroutine 8:
  main.(*Counter).increment()
      /path/to/main.go:13 +0x3c
...
Found 1 data race(s)
exit status 66
```

The race detector identifies unsynchronized reads/writes to shared memory and warns us.

---

## üß© 2Ô∏è‚É£ Version WITH Mutex (Safe One)

Now compare it with your earlier code:

```go
func (c *Counter) increment() {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.val++
}
```

Now:

* Only **one goroutine** can perform `c.val++` at a time.
* The others **wait** at `Lock()` until it‚Äôs released.
* So, all 1000 increments are guaranteed to complete without data loss.

‚úÖ Output will **always** be:

```
‚úÖ Final counter val: 1000
```

---

## üß† Summary

| Concept                    | Without Mutex                       | With Mutex                      |
| -------------------------- | ----------------------------------- | ------------------------------- |
| Access type                | Concurrent                          | Synchronized                    |
| Data safety                | ‚ùå Race condition                    | ‚úÖ Safe                          |
| Output consistency         | Unpredictable                       | Always 1000                     |
| CPU instructions (`val++`) | Read ‚Üí Add ‚Üí Write (can interleave) | Executes atomically inside Lock |
| Debugging help             | Use `go run -race .`                | Race detector shows no issue    |

---

## üß© Real-World Analogy

Imagine 10 people (goroutines) trying to **update a whiteboard** at the same time.

* Without rules (mutex): they bump into each other, overwrite numbers, and cause chaos.
* With a rule (mutex): only one person writes at a time while others wait ‚Äî result stays correct.

---

